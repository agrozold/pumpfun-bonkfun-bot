"""
Trending Token Scanner - —Å–∫–∞–Ω–∏—Ä—É–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–æ–∫–µ–Ω—ã –Ω–∞ pump.fun.

–ù–∞—Ö–æ–¥–∏—Ç —Ç–æ–∫–µ–Ω—ã —Å —Ä–µ–∑–∫–∏–º —Ä–æ—Å—Ç–æ–º –æ–±—ä—ë–º–∞/—Ü–µ–Ω—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —á–∞—Å—ã.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç DexScreener API (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π, –±–µ–∑ –ª–∏–º–∏—Ç–æ–≤).
"""

import asyncio
import logging
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Callable

import aiohttp

logger = logging.getLogger(__name__)

DEXSCREENER_API = "https://api.dexscreener.com"


@dataclass
class TrendingToken:
    """–¢—Ä–µ–Ω–¥–æ–≤—ã–π —Ç–æ–∫–µ–Ω."""
    mint: str
    symbol: str
    name: str
    price_usd: float
    volume_24h: float
    volume_1h: float
    volume_5m: float
    market_cap: float
    price_change_5m: float
    price_change_1h: float
    price_change_24h: float
    buys_5m: int
    sells_5m: int
    buys_1h: int
    sells_1h: int
    liquidity: float
    created_at: datetime | None
    
    @property
    def buy_pressure_5m(self) -> float:
        """–ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–∫—É–ø–æ–∫ –∑–∞ 5 –º–∏–Ω—É—Ç."""
        total = self.buys_5m + self.sells_5m
        return self.buys_5m / total if total > 0 else 0
    
    @property
    def buy_pressure_1h(self) -> float:
        """–ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–∫—É–ø–æ–∫ –∑–∞ 1 —á–∞—Å."""
        total = self.buys_1h + self.sells_1h
        return self.buys_1h / total if total > 0 else 0
    
    @property
    def trade_velocity(self) -> int:
        """–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫ –∑–∞ 5 –º–∏–Ω—É—Ç."""
        return self.buys_5m + self.sells_5m
    
    @property
    def volume_ratio(self) -> float:
        """–û—Ç–Ω–æ—à–µ–Ω–∏–µ –æ–±—ä—ë–º–∞ 5–º –∫ —Å—Ä–µ–¥–Ω–µ–º—É 5–º –∑–∞ —á–∞—Å."""
        # 12 –ø–µ—Ä–∏–æ–¥–æ–≤ –ø–æ 5 –º–∏–Ω—É—Ç –≤ —á–∞—Å–µ
        avg_5m = self.volume_1h / 12 if self.volume_1h > 0 else 0
        return self.volume_5m / avg_5m if avg_5m > 0 else 0


class TrendingScanner:
    """–°–∫–∞–Ω–µ—Ä —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ pump.fun."""

    def __init__(
        self,
        # –§–∏–ª—å—Ç—Ä—ã
        min_volume_1h: float = 50000,        # –ú–∏–Ω–∏–º—É–º $50k –æ–±—ä—ë–º–∞ –∑–∞ 1 —á–∞—Å!
        min_market_cap: float = 10000,       # –ú–∏–Ω–∏–º—É–º $10k –º–∞—Ä–∫–µ—Ç–∫–∞–ø
        max_market_cap: float = 5000000,     # –ú–∞–∫—Å–∏–º—É–º $5M (–Ω–µ —Å–ª–∏—à–∫–æ–º –ø–æ–∑–¥–Ω–æ)
        min_liquidity: float = 5000,         # –ú–∏–Ω–∏–º—É–º $5k –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏
        max_token_age_hours: float = 24,     # –¢–æ–∫–µ–Ω—ã –Ω–µ —Å—Ç–∞—Ä—à–µ 24 —á–∞—Å–æ–≤
        # –¢—Ä–∏–≥–≥–µ—Ä—ã –¥–ª—è –ø–æ–∫—É–ø–∫–∏ - –†–ï–ó–ö–ò–ô –í–°–ü–õ–ï–°–ö
        min_price_change_5m: float = 5,      # –ú–∏–Ω–∏–º—É–º +5% –∑–∞ 5 –º–∏–Ω—É—Ç
        min_price_change_1h: float = 20,     # –ú–∏–Ω–∏–º—É–º +20% –∑–∞ —á–∞—Å
        min_buy_pressure: float = 0.65,      # 65% –ø–æ–∫—É–ø–æ–∫ (—Ä–µ–∑–∫–∏–π buy)
        min_trade_velocity: int = 15,        # 15+ —Å–¥–µ–ª–æ–∫ –∑–∞ 5 –º–∏–Ω
        min_volume_ratio: float = 3.0,       # –û–±—ä—ë–º 5–º –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 3x –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        scan_interval: float = 30,           # –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫
        max_concurrent_buys: int = 3,        # –ú–∞–∫—Å –ø–æ–∫—É–ø–æ–∫ –∑–∞ —Ü–∏–∫–ª
    ):
        self.min_volume_1h = min_volume_1h
        self.min_market_cap = min_market_cap
        self.max_market_cap = max_market_cap
        self.min_liquidity = min_liquidity
        self.max_token_age_hours = max_token_age_hours
        
        self.min_price_change_5m = min_price_change_5m
        self.min_price_change_1h = min_price_change_1h
        self.min_buy_pressure = min_buy_pressure
        self.min_trade_velocity = min_trade_velocity
        self.min_volume_ratio = min_volume_ratio
        
        self.scan_interval = scan_interval
        self.max_concurrent_buys = max_concurrent_buys
        
        # State
        self._session: aiohttp.ClientSession | None = None
        self._running = False
        self._scan_task: asyncio.Task | None = None
        self.on_trending_token: Callable | None = None
        
        # Track already processed tokens (avoid duplicates)
        self.processed_tokens: set[str] = set()
        self.processed_tokens_timestamps: dict[str, float] = {}
        
        logger.info(
            f"TrendingScanner initialized: "
            f"min_vol_1h=${min_volume_1h:,.0f}, "
            f"min_mc=${min_market_cap:,.0f}, "
            f"max_mc=${max_market_cap:,.0f}, "
            f"min_change_5m={min_price_change_5m}%, "
            f"min_buy_pressure={min_buy_pressure*100:.0f}%"
        )

    def set_callback(self, callback: Callable):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å callback –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤."""
        self.on_trending_token = callback

    async def start(self):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–∫–∞–Ω–µ—Ä."""
        if self._running:
            return
        
        self._running = True
        self._session = aiohttp.ClientSession()
        self._scan_task = asyncio.create_task(self._scan_loop())
        logger.info("üîç Trending scanner started")

    async def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–∫–∞–Ω–µ—Ä."""
        self._running = False
        if self._scan_task:
            self._scan_task.cancel()
        if self._session:
            await self._session.close()
        logger.info("Trending scanner stopped")

    async def _scan_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è."""
        while self._running:
            try:
                await self._scan_trending()
                await asyncio.sleep(self.scan_interval)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.exception(f"Scan error: {e}")
                await asyncio.sleep(10)

    async def _scan_trending(self):
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–µ–Ω–¥–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã."""
        # Cleanup old processed tokens (older than 1 hour)
        self._cleanup_processed()
        
        # Get trending tokens from DexScreener
        tokens = await self._fetch_pump_tokens()
        if not tokens:
            logger.debug("No tokens fetched from DexScreener")
            return
        
        logger.info(f"üîç Scanned {len(tokens)} pump.fun tokens from DexScreener")
        
        # Filter and score tokens
        candidates = []
        for token in tokens:
            if token.mint in self.processed_tokens:
                continue
            
            score, reasons = self._evaluate_token(token)
            if score > 0:
                candidates.append((token, score, reasons))
        
        if candidates:
            logger.info(f"üìä Found {len(candidates)} candidates passing filters")
        
        # Sort by score and take top candidates
        candidates.sort(key=lambda x: x[1], reverse=True)
        
        for token, score, reasons in candidates[:self.max_concurrent_buys]:
            logger.warning(
                f"üî• TRENDING: {token.symbol} - "
                f"MC: ${token.market_cap:,.0f}, "
                f"Vol24h: ${token.volume_24h:,.0f}, "
                f"Change1h: {token.price_change_1h:+.1f}%, "
                f"Score: {score}"
            )
            for reason in reasons:
                logger.info(f"   ‚úì {reason}")
            
            # Mark as processed
            self.processed_tokens.add(token.mint)
            self.processed_tokens_timestamps[token.mint] = datetime.utcnow().timestamp()
            
            # Trigger callback
            if self.on_trending_token:
                await self.on_trending_token(token)

    async def _fetch_pump_tokens(self) -> list[TrendingToken]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω—ã pump.fun —Å DexScreener."""
        if not self._session:
            return []
        
        tokens = []
        
        try:
            # DexScreener search for pump.fun tokens
            # Using boosted tokens endpoint for trending
            url = f"{DEXSCREENER_API}/token-boosts/top/v1"
            
            async with self._session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as resp:
                if resp.status != 200:
                    logger.debug(f"DexScreener boosts error: {resp.status}")
                    # Fallback to search
                    return await self._fetch_pump_tokens_search()
                
                data = await resp.json()
                
                for item in data:
                    # Filter only pump.fun tokens (Solana + pump suffix)
                    token_addr = item.get("tokenAddress", "")
                    chain = item.get("chainId", "")
                    
                    if chain != "solana" or not token_addr.endswith("pump"):
                        continue
                    
                    # Get detailed info
                    detail = await self._fetch_token_detail(token_addr)
                    if detail:
                        tokens.append(detail)
                    
                    await asyncio.sleep(0.2)  # Rate limit
                    
                    if len(tokens) >= 20:  # Limit
                        break
        
        except Exception as e:
            logger.debug(f"Fetch boosts error: {e}")
            return await self._fetch_pump_tokens_search()
        
        return tokens

    async def _fetch_pump_tokens_search(self) -> list[TrendingToken]:
        """Fallback - –ø–æ–∏—Å–∫ pump.fun —Ç–æ–∫–µ–Ω–æ–≤."""
        if not self._session:
            return []
        
        tokens = []
        
        try:
            # Search for recent pump.fun tokens
            url = f"{DEXSCREENER_API}/latest/dex/search?q=pump"
            
            async with self._session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as resp:
                if resp.status != 200:
                    return []
                
                data = await resp.json()
                pairs = data.get("pairs", [])
                
                for pair in pairs:
                    # Filter pump.fun on Solana
                    if pair.get("chainId") != "solana":
                        continue
                    
                    base = pair.get("baseToken", {})
                    addr = base.get("address", "")
                    
                    if not addr.endswith("pump"):
                        continue
                    
                    token = self._parse_pair(pair)
                    if token:
                        tokens.append(token)
                    
                    if len(tokens) >= 30:
                        break
        
        except Exception as e:
            logger.debug(f"Search error: {e}")
        
        return tokens

    async def _fetch_token_detail(self, mint: str) -> TrendingToken | None:
        """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ —Ç–æ–∫–µ–Ω–∞."""
        if not self._session:
            return None
        
        try:
            url = f"{DEXSCREENER_API}/latest/dex/tokens/{mint}"
            
            async with self._session.get(url, timeout=aiohttp.ClientTimeout(total=5)) as resp:
                if resp.status != 200:
                    return None
                
                data = await resp.json()
                pairs = data.get("pairs", [])
                
                if pairs:
                    return self._parse_pair(pairs[0])
        
        except Exception as e:
            logger.debug(f"Token detail error: {e}")
        
        return None

    def _parse_pair(self, pair: dict) -> TrendingToken | None:
        """–ü–∞—Ä—Å–∏—Ç—å –ø–∞—Ä—É –≤ TrendingToken."""
        try:
            base = pair.get("baseToken", {})
            txns = pair.get("txns", {})
            m5 = txns.get("m5", {})
            h1 = txns.get("h1", {})
            volume = pair.get("volume", {})
            
            # Parse creation time
            created_at = None
            if pair.get("pairCreatedAt"):
                created_at = datetime.fromtimestamp(pair["pairCreatedAt"] / 1000)
            
            return TrendingToken(
                mint=base.get("address", ""),
                symbol=base.get("symbol", ""),
                name=base.get("name", ""),
                price_usd=float(pair.get("priceUsd", 0) or 0),
                volume_24h=float(volume.get("h24", 0) or 0),
                volume_1h=float(volume.get("h1", 0) or 0),
                volume_5m=float(volume.get("m5", 0) or 0),
                market_cap=float(pair.get("marketCap", 0) or 0),
                price_change_5m=float(pair.get("priceChange", {}).get("m5", 0) or 0),
                price_change_1h=float(pair.get("priceChange", {}).get("h1", 0) or 0),
                price_change_24h=float(pair.get("priceChange", {}).get("h24", 0) or 0),
                buys_5m=m5.get("buys", 0),
                sells_5m=m5.get("sells", 0),
                buys_1h=h1.get("buys", 0),
                sells_1h=h1.get("sells", 0),
                liquidity=float(pair.get("liquidity", {}).get("usd", 0) or 0),
                created_at=created_at,
            )
        except Exception as e:
            logger.debug(f"Parse error: {e}")
            return None

    def _evaluate_token(self, token: TrendingToken) -> tuple[int, list[str]]:
        """–û—Ü–µ–Ω–∏—Ç—å —Ç–æ–∫–µ–Ω. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (score, reasons)."""
        score = 0
        reasons = []
        
        # Basic filters - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï
        if token.volume_1h < self.min_volume_1h:
            return 0, []
        
        if token.market_cap < self.min_market_cap:
            return 0, []
        
        if token.market_cap > self.max_market_cap:
            return 0, []
        
        if token.liquidity < self.min_liquidity:
            return 0, []
        
        # Age filter
        if token.created_at:
            age_hours = (datetime.utcnow() - token.created_at).total_seconds() / 3600
            if age_hours > self.max_token_age_hours:
                return 0, []
        
        # === –ö–†–ò–¢–ï–†–ò–ò –†–ï–ó–ö–û–ì–û –í–°–ü–õ–ï–°–ö–ê ===
        
        # 1. –†–µ–∑–∫–∏–π —Ä–æ—Å—Ç —Ü–µ–Ω—ã –∑–∞ 5 –º–∏–Ω—É—Ç (–í–ê–ñ–ù–û!)
        if token.price_change_5m >= self.min_price_change_5m:
            score += 35
            reasons.append(f"üöÄ Price +{token.price_change_5m:.1f}% in 5min!")
        elif token.price_change_1h >= self.min_price_change_1h:
            # –ò–ª–∏ —Ö–æ—Ä–æ—à–∏–π —Ä–æ—Å—Ç –∑–∞ —á–∞—Å
            score += 25
            reasons.append(f"üìà Price +{token.price_change_1h:.1f}% in 1h")
        else:
            # –ë–µ–∑ —Ä–æ—Å—Ç–∞ - –Ω–µ –ø–æ–∫—É–ø–∞–µ–º
            return 0, []
        
        # 2. Buy pressure –∑–∞ 5 –º–∏–Ω—É—Ç (–±–æ–Ω—É—Å, –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
        if token.buy_pressure_5m >= self.min_buy_pressure:
            score += 30
            reasons.append(f"üí™ Buy pressure {token.buy_pressure_5m*100:.0f}% (5m)")
        elif token.buy_pressure_5m >= 0.5:
            score += 15
            reasons.append(f"üëç Buy pressure {token.buy_pressure_5m*100:.0f}% (5m)")
        
        # 3. Trade velocity (–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å)
        if token.trade_velocity >= self.min_trade_velocity:
            score += 20
            reasons.append(f"‚ö° {token.trade_velocity} trades in 5min")
        
        # 4. Volume ratio (–≤—Å–ø–ª–µ—Å–∫ –æ–±—ä—ë–º–∞)
        if token.volume_ratio >= self.min_volume_ratio:
            score += 15
            reasons.append(f"üìà Volume {token.volume_ratio:.1f}x average")
        
        # 5. –ë–æ–Ω—É—Å –∑–∞ —Ä–æ—Å—Ç –∑–∞ —á–∞—Å
        if token.price_change_1h >= self.min_price_change_1h:
            score += 10
            reasons.append(f"üìä +{token.price_change_1h:.1f}% in 1h")
        
        # 6. –ë–æ–Ω—É—Å –∑–∞ —Ä–∞–Ω–Ω–∏–π –º–∞—Ä–∫–µ—Ç–∫–∞–ø
        if 20000 <= token.market_cap <= 200000:
            score += 10
            reasons.append(f"üéØ Early MC: ${token.market_cap:,.0f}")
        
        return score, reasons

    def _cleanup_processed(self):
        """–û—á–∏—Å—Ç–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã."""
        now = datetime.utcnow().timestamp()
        cutoff = now - 3600  # 1 hour
        
        to_remove = [
            mint for mint, ts in self.processed_tokens_timestamps.items()
            if ts < cutoff
        ]
        
        for mint in to_remove:
            self.processed_tokens.discard(mint)
            self.processed_tokens_timestamps.pop(mint, None)
